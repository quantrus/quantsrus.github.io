<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Quants R Us</title>
    <link>https://quantsrus.github.io/post/</link>
    <description>Recent content in Posts on Quants R Us</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Dec 2017 22:48:01 +0200</lastBuildDate>
    
	<atom:link href="https://quantsrus.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Webassembly still fragile</title>
      <link>https://quantsrus.github.io/post/webassembly_still_fragile/</link>
      <pubDate>Tue, 05 Dec 2017 22:48:01 +0200</pubDate>
      
      <guid>https://quantsrus.github.io/post/webassembly_still_fragile/</guid>
      <description>As I am preparing the website for my upcoming book on equity derivatives models, I played around with webassembly to run some C++ code from your web browser. In order to do that, I rely on emscripten, which seems to be the most advanced toolkit to generate webassembly code.
I did not expect the webassembly toolchain to be so fragile. At first I had trouble using some specific C code (not so complicated) from javascript through emscripten: there are multiple ways to do it.</description>
    </item>
    
    <item>
      <title>Particle Swarm Optimization on Heston Small-Time Expansion</title>
      <link>https://quantsrus.github.io/post/particle_swarm_optimization_heston_calibration/</link>
      <pubDate>Thu, 06 Jul 2017 07:48:01 +0200</pubDate>
      
      <guid>https://quantsrus.github.io/post/particle_swarm_optimization_heston_calibration/</guid>
      <description>This is a sequel to my previous post on Particle Swarm Optimization. Here, I look at the problem of &amp;ldquo;calibrating&amp;rdquo; a Heston small-time expansion, the one from Forde &amp;amp; Jacquier). This can be useful to find a good initial guess for the exact Heston calibration, computed with much costlier characteristic function Fourier numerical integration.
Unfortunately, as we see below, with the contour plots of the objective function (the RMSE in volatilities against market quotes), the problem is much less well behaved with the small-time expansion than with the numerical integration.</description>
    </item>
    
    <item>
      <title>Particle Swarm Optimization</title>
      <link>https://quantsrus.github.io/post/particle_swarm_optimization/</link>
      <pubDate>Fri, 30 Jun 2017 07:48:01 +0200</pubDate>
      
      <guid>https://quantsrus.github.io/post/particle_swarm_optimization/</guid>
      <description>In my previous post, I looked at simulated annealing to calibrate Heston. A less well-known and more fancy global minimizer is the particle swarm optimization (PSO). I stumbled upon it by accident through a youtube presentation from James McCaffrey. He shows a small python algorithm that solves the travelling salesman problem.
Intrigued, I started to read papers on it. It turns out there are a lot of publications on PSO, not always of great quality.</description>
    </item>
    
    <item>
      <title>Differential evolution vs. Simulated annealing</title>
      <link>https://quantsrus.github.io/post/differential_evolution_vs_simulated_annealing/</link>
      <pubDate>Wed, 21 Jun 2017 22:48:01 +0200</pubDate>
      
      <guid>https://quantsrus.github.io/post/differential_evolution_vs_simulated_annealing/</guid>
      <description>The differential evolution (DE) algorithm is somewhat popular in quantitative finance, for example to calibrate stochastic volatility models such as Heston. There are a few parameters to setup properly but in general, it is not too difficult to find those, and the algorithm works well on many different problems.
An older technique, much more popular in physics is simulated annealing (SA). There are few papers on its use for stochastic volatility calibration, most don&amp;rsquo;t find the technique competitive (the ASA algorithm appear very slow in this paper from Ricardo Crisostomo, more standard SA is worse than a random search according to ManWo Ng) or even usable (see Jorg Kienitz book).</description>
    </item>
    
    <item>
      <title>A spline to fill the gaps with Andreasen-Huge one-step method</title>
      <link>https://quantsrus.github.io/post/andreasen_huge_spline/</link>
      <pubDate>Thu, 11 May 2017 22:48:01 +0200</pubDate>
      
      <guid>https://quantsrus.github.io/post/andreasen_huge_spline/</guid>
      <description>I recently stumbled upon a blog which suggested to not stay flat with Andreasen-Huge arbitrage free volatility interpolation method. The paper from Andreasen and Huge specifies a piecewise constant (single-step) local volatility where the number of constants matches the number of market option prices.
The blog post shows eventual unstability with the piecewise constant approach, not visible with a linear interpolation. I wondered then if we should not go to the next level: use a spline on N values where N is the number of market options prices.</description>
    </item>
    
  </channel>
</rss>